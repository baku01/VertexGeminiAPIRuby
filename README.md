# API com Sinatra: IntegraÃ§Ã£o do Vertex AI e Gemini ğŸš€

Este projeto Ã© uma API construÃ­da com o framework Sinatra para interagir com o Vertex AI da Google e o Gemini. Ele permite que os usuÃ¡rios enviem perguntas atravÃ©s de um endpoint HTTP POST e recebam respostas processadas por modelos de inteligÃªncia artificial avanÃ§ados.

## ConfiguraÃ§Ã£o ğŸ› 

Este projeto utiliza Ruby e o framework Sinatra. Certifique-se de ter Ruby instalado em sua mÃ¡quina.

### DependÃªncias

Para instalar as dependÃªncias do projeto, execute:

```bash
bundle install
```

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto e adicione as seguintes chaves de API:

```
GEMINI_API_KEY=sua_chave_api_gemini_aqui
```

Certifique-se de ter configurado as credenciais de acesso para a API do Google.

## Detalhes do CÃ³digo

### Classe `GeminiService`

A classe `GeminiService` Ã© responsÃ¡vel pela interaÃ§Ã£o com a API do Gemini. Abaixo estÃ¡ o mÃ©todo `initialize` que configura o cliente:

```ruby
def initialize
  @gemini_client = Gemini.new(
    credentials: { service: 'generative-language-api', api_key: ENV['GEMINI_API_KEY'] },
    options: { model: 'gemini-pro' }
  )
end
```

- **InicializaÃ§Ã£o**: Este trecho configura o cliente Gemini com a chave de API fornecida e o modelo desejado.

O mÃ©todo `generate_content` envia o texto recebido e processa a resposta:

```ruby
def generate_content(text)
  request_params = {
    contents: {
      role: 'user',
      parts: { text: text }
    }
  }
  @gemini_client.stream_generate_content(request_params).map do |response|
    response.dig('candidates', 0, 'content', 'parts', 0, 'text').gsub(/[\n\\*#]+/, ' ')
  end.join(" ")
end
```

- **GeraÃ§Ã£o de ConteÃºdo**: O mÃ©todo processa o texto fornecido, enviando-o para a API e ajustando a resposta para remover caracteres especiais.

### Endpoint Sinatra `/gemini-ai`

O cÃ³digo a seguir configura um endpoint POST em `/gemini-ai` que trata as requisiÃ§Ãµes:

```ruby
post '/gemini-ai' do
  content_type :text  # Define o tipo de conteÃºdo da resposta como texto
  question = params["question"]  # Recupera a questÃ£o do corpo da requisiÃ§Ã£o

  begin
    response = GeminiService.new.call(question)
  rescue StandardError => error
    status 500
    "Erro ao processar a requisiÃ§Ã£o: #{error.message}"
  end
end
```

- **Endpoint POST**: Este cÃ³digo define como a API recebe e responde a perguntas enviadas pelos usuÃ¡rios.

## Executando a AplicaÃ§Ã£o ğŸƒâ€â™‚ï¸

Para iniciar o servidor, execute:

```bash
ruby app.rb
```

## Uso ğŸ“¡

Envie uma requisiÃ§Ã£o POST para `http://localhost:4567/gemini-ai` com um corpo de requisiÃ§Ã£o que inclua uma `question` para obter uma resposta processada pelo serviÃ§o de IA.

```bash
curl -X POST -d "question=sua_pergunta_aqui" http://localhost:4567/gemini-ai
```

## ContribuiÃ§Ãµes ğŸ‘¥

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir, faÃ§a um fork do repositÃ³rio, crie uma branch para sua funcionalidade e submeta um pull request.
